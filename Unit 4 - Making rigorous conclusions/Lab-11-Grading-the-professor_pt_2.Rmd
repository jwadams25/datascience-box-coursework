---
title: "Lab 11 - Grading the professor, Pt. 2"
author: "John Adams"
date: "3/10/22"
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
library(broom)
```

### Exercise 1

```{r data }
glimpse(evals)
```

### Exercise 2

Fit a linear model (one you have fit before): score_bty_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) only. Write the linear model, and note the R2 and the adjusted R2.


score = 3.88 + 0.06664 x bty_avg

Multiple R-squared:  0.03502,	Adjusted R-squared:  0.03293 


```{r score bty}
score_bty_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals)

score_bty_fit

summary(lm(formula = evals$score ~ evals$bty_avg))

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals) %>%
  tidy()
```

### Exercises 3 & 4

Fit a linear model (one you have fit before): score_bty_gen_fit, predicting average professor evaluation score based on average beauty rating (bty_avg) and gender. Write the linear model, and note the R2 and the adjusted R2.

All else held constant, for each additional point increase in a professors average beauty rating, we would expect their average evaluation score to increase by 0.074 points. 

All else held constant, males earn, on average, roughly 0.17 higher average evaluation scores than female professors. 

The doesn't make sense in this context because it would be a female with a beauty rating of 0. 

```{r score bty gender}

score_bty_gen_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + gender, data = evals)

glance(score_bty_gen_fit)$r.squared

linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + gender, data = evals) %>%
  tidy()


```

### Exercise 5 

5.9% of the variation in scores is explained by our model. 

Visualize above relationship

```{r score bty gender viz}
evals %>%
  ggplot(aes(x = bty_avg, y = score, color = gender)) +
  geom_jitter() +
  labs(
    title = "Is there a relationship between a professors gender and beauty rating \non their average evaluation score?", 
    x = "Average Beauty Rating",
    y = "Average Evaluation Score",
    color = "Gender of Professor"
  ) +
  theme_minimal()

evals %>%
  ggplot(aes(x = bty_avg, y = score, color = gender)) +
  geom_jitter() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    title = "Is there a relationship between a professors gender and beauty rating \non their average evaluation score?", 
    x = "Average Beauty Rating",
    y = "Average Evaluation Score",
    color = "Gender of Professor"
  ) +
  theme_minimal() +
  facet_wrap(~gender, ncol = 2)
```

### Exercise 6

score = 3.7473 + 0.0741 x bty_avg + 0.172

### Exercise 7 
For two professors who received the same beauty rating, which gender tends to have the higher course evaluation score?

Male professors

### Exercise 8 

### Exercise 9 

Since the model with gender has a higher adjusted r-squared than the model without gender tells us that gender is in fact useful in explaining the variability of a professors average evaluation score. 

```{r comparing with adjusted r squared}

glance(score_bty_fit)$adj.r.squared > glance(score_bty_gen_fit)$adj.r.squared


```

### Exercise 10

The slope of bty_avg is slightly more in the model that includes both gender and bty_avg than the one that only includes bty_avg (0.074 vs 0.067)

### Exercise 11

Create a new model called score_bty_rank_fit with gender removed and rank added in. Write the equation of the linear model and interpret the slopes and intercept in context of the data.

score = 3.98155
        + 0.06783 x bty_avg 
        - 0.16070 x rank_tenture_track 
        - 0.12623 x rank_tenure
        
All else held constant, for each additional point increase in a professors average beauty rating, we would expect their average evaluation score to increase by 0.068 points.

All else held constant, we would exp


```{r score bty rank}
score_bty_rank_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + rank, data = evals)

score_bty_rank_fit

glance(score_bty_rank_fit)$r.squared > glance(score_bty_fit)$adj.r.squared
```


