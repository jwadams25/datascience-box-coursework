---
title: "Lab 10 - Grading the professor, Pt. 1"
author: "John Adams"
date: "3/10/22"
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
library(skimr)
library(gridExtra)
```

### Data
```{r data}
glimpse(evals)
```

### Exercise 1
Visualize the distribution of score. 
a. Is the distribution skewed? What does that tell you about how students rate courses? Is this what you expected to see? Why, or why not? Include any summary statistics and visualizations you use in your response.

The distribution of scores is skewed to the left, which tells you that students tend to rate courses really high (median = 4.3) and occasion rate courses lower. 75% of courses are rated higher than a 3.8. This matches my expectation because most classes I've had tend to be good and then there is always one or two that were not so good. 

```{r exercise 1}
evals %>%
  ggplot(aes(x = score)) +
  geom_histogram(binwidth = 0.1, color = "#FFFFFF", fill = "navy")

evals %>%
  select(score) %>%
  skim()

evals %>%
  select(bty_avg) %>%
  skim()
```



### Exercises 2 and 3

Geom_Jitter prevents overplotting by moving dots that overlap a random amount left and right. Given that score is descrete and there are 463 observations, some of those observations overlap, which means when looking at the visualization, you are not seeing all of the data. I plotted a geom_point with an alpha of 0.25 to also uncover the overlapping. 

```{r score vs bty avg}
score_point <- evals %>%
                ggplot(aes(y = score, x = bty_avg)) +
                geom_point()

score_point_alpha <- evals %>%
                      ggplot(aes(y = score, x = bty_avg)) +
                      geom_point(alpha = 0.25)

score_jitter <- evals %>%
                  ggplot(aes(y = score, x = bty_avg)) +
                  geom_jitter()

grid.arrange(score_point, score_point_alpha, score_jitter, nrow = 2, ncol = 2)

```

### Exercise 4 
Letâ€™s see if the apparent trend in the plot is something more than natural variation. Fit a linear model called score_bty_fit to predict average professor evaluation score by average beauty rating (bty_avg). Based on the regression output, write the linear model.

score = 3.88 + 0.06664 x bty_avg

```{r linear model}

score_bty_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals) %>%
  tidy()

score_bty_fit

```
### Exercise 5
Recreate the scatterplot from Exercise 2, and add the regression line to this plot in orange colour, with shading for the uncertainty of the line turned off.

```{r plot with line}
score_jitter <- evals %>%
                  ggplot(aes(y = score, x = bty_avg)) +
                  geom_jitter() +
                  geom_smooth(method = lm, se = FALSE)
score_jitter

```

### Exercises 6-7

Based on this model, we can expect that a professors average evaluation score will rise on average by 0.066 points for each additional point increase in their average beauty rating. 

The y-intercept would mean that a teacheer will earn an average evaluation score of 3.88 if they have a 0 beauty rating. The lowest beauty score in this dataset is a 1.67 and, in general, it's hard to imagine a professor getting a beauty rating of 0, which makes the y-intercept meaningless in this case. 

### Exercise 8 

3.5% of the variation in a professors average evaluation score can be explained by their average beauty rating. 

```{r correlation}

evals %>%
  summarise(
    r = cor(score, bty_avg), 
    r_squared = (cor(score, bty_avg))^2
  )

```

# Linear regression with a categorical predictor

### Exercises 9 & 10
Fit a new linear model called score_bty_gender to predict average professor evaluation score based on gender of the professor. Based on the regression output, write the linear model and interpret the slope and intercept in context of the data.

score = 4.23 - 0.1415 x gender

male = 0
female = 1

score_male = 4.23
score_female = 4.23 - 0.1415 = 4.1585

Female professors are expected, on average, to receive an evaluation score that is 0.14 points lower than male professors. 

```{r score gender}

evals <- evals %>%
          mutate(gender_num = ifelse(gender == "male", 0, 1))

score_gender_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ factor(gender_num), data = evals) %>%
  tidy()

score_gender_fit


```

### Exercise 11 - 13

Tenure track professors are expected, on average, to earn an average evaluation score of 4.15. 
Teaching professors are expected, on average, to earn an average evaluation score that is 0.13 points higher than a tenure track professor. Tenured professors are expected, on average, to earn an average evaluation score that is 0.015 points lower than a tenure track professor.

1.1 percent of the variation in average evaluation score can be explained by the professor rank. 


```{r}
evals %>%
  group_by(rank) %>%
  summarise(
    n = n()
  )

score_rank_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ factor(rank), data = evals) %>%
  tidy()

score_rank_fit

evals <- evals %>%
          mutate(rank_level = relevel(evals$rank, ref = "tenure track"))

score_rank_eval_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank_level, data = evals) %>%
  tidy()

score_rank_eval_fit

summary(lm(formula = evals$score ~ evals$rank_level))

```
### Exercises 14 & 15

Create another new variable called tenure_eligible that labels "teaching" faculty as "no" and labels "tenure track" and "tenured" faculty as "yes".

Professors with the rank of teaching  are expected to, on average, earn an average evaluation score of 4.28. On the other hand, professors with any other rank are expected, on average, to earn an average evaluation score that is  0.14 poins lower than the professors with the rank of teaching. 

1.15 percent of the variation in evaluation score can be explained by whether or not the professor has a rank of teaching. 

```{r teaching }
evals <- evals %>%
          mutate(tenure_eligible = if_else(evals$rank == "teaching", "no", "yes")) 

score_ten_eli_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ tenure_eligible, data = evals) %>%
  tidy()

score_ten_eli_fit

summary(lm(formula = evals$score ~ evals$tenure_eligible))


```

